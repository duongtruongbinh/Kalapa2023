{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown 12WhRAutMZ_PKEWAYyxKk6MJ_hZ9t6g_q\n",
        "#https://drive.google.com/file/d/12WhRAutMZ_PKEWAYyxKk6MJ_hZ9t6g_q/view?usp=drive_link"
      ],
      "metadata": {
        "id": "RVQ3i8sgzeqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.34.0 datasets==2.14.5 accelerate==0.23.0 evaluate==0.4.1 peft==0.5.0"
      ],
      "metadata": {
        "id": "F4Y6TPyB792f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "id2label = {0: 'A',\n",
        "            1: 'B',\n",
        "            2: 'C',\n",
        "            3: 'D',\n",
        "            4: 'E'}\n",
        "label2id = {'A': 0,\n",
        "            'B': 1,\n",
        "            'C': 2,\n",
        "            'D': 3,\n",
        "            'E': 4}\n",
        "num_labels = len(id2label)\n",
        "\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          num_labels=num_labels,\n",
        "                                          label2id=label2id,\n",
        "                                          id2label=id2label,\n",
        "                                          use_fast=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                           num_labels=num_labels)\n",
        "\n",
        "# peft_config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.05, target_modules=[\"query\", \"vavlue\"], bias=\"none\")\n",
        "# model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl6sGAc67fBD",
        "outputId": "6586eb2f-b310-4df6-a88b-b46f81860e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model.load_state_dict(torch.load(\"./pytorch_model.bin\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osc6tVIQ7nbP",
        "outputId": "c1523172-b175-4816-aaa8-5b531c81452f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_binary = {0: '10000',\n",
        "                     1: '01000',\n",
        "                     2: '00100',\n",
        "                     3: '00010',\n",
        "                     4: '00001'}\n",
        "\n",
        "def predict_per_sample(df, model, tokenizer):\n",
        "    answers = []\n",
        "    for idx, row in df.iterrows():\n",
        "        context = row[\"retrieved_context\"]\n",
        "        question = row[\"question\"]\n",
        "        choices = [op for op in row[[\"option_1\", \"option_2\", \"option_3\", \"option_4\", \"option_5\", \"option_6\"]].tolist() if isinstance(op, str)]\n",
        "        text_choices = \" \".join(choices)\n",
        "        prompt = f\"Question: {question}. Choice the correct answers from: {text_choices}. Context: {context}\"\n",
        "        model_inputs = tokenizer(prompt, max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "        outputs = model(**model_inputs)\n",
        "        prediction = torch.argmax(outputs[0], axis=1)\n",
        "        answer = convert_to_binary[prediction.item()]\n",
        "        answer = answer[:len(choices)]\n",
        "        answers.append(answer)\n",
        "    return answers"
      ],
      "metadata": {
        "id": "yf3a58Hj8sLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/updated_en_test_data_v2.csv\") #testset\n",
        "answers = predict_per_sample(df, model, tokenizer)\n",
        "df['answer'] = answers\n",
        "result_df = df[[\"id\", \"answer\"]]\n",
        "result_df.to_csv(\"/content/updated_answer_en_test_data_v2.csv\")"
      ],
      "metadata": {
        "id": "twADBFvD85ER"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}